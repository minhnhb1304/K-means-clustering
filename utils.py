import streamlit as st
import pandas as pd
import numpy as np
import joblib
import os
from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import silhouette_score


class BookClusteringAI:
    """
    Class AI Ä‘á»ƒ phÃ¢n cá»¥m vÃ  dá»± bÃ¡o sÃ¡ch sá»­ dá»¥ng K-Means Clustering.
    """
    
    def __init__(self):
        """Khá»Ÿi táº¡o BookClusteringAI"""
        self.model = None
        self.scaler = None
        self.cluster_label_mapping = {}  # Mapping tá»« cluster_id -> label (Trend/Potential/Risk/Standard)
        self.features = ['quantity', 'n_review', 'avg_rating']
        self.model_path = 'kmeans_model.pkl'
        self.scaler_path = 'scaler.pkl'
        self.mapping_path = 'cluster_mapping.pkl'
        self.df_processed = None
        self.X_scaled = None
    
    def load_data(self, uploaded_file):
        return pd.read_csv(uploaded_file)
    
    def preprocess_data(self, df):
        # Táº¡o báº£n sao
        df_processed = df.copy()
        
        # Loáº¡i bá» cÃ¡c dÃ²ng cÃ³ giÃ¡ trá»‹ thiáº¿u trong cÃ¡c Ä‘áº·c trÆ°ng
        df_processed = df_processed.dropna(subset=self.features)
        
        # Chuáº©n hÃ³a dá»¯ liá»‡u
        scaler = StandardScaler()
        X_scaled = scaler.fit_transform(df_processed[self.features])
        
        # LÆ°u vÃ o instance
        self.df_processed = df_processed
        self.X_scaled = X_scaled
        self.scaler = scaler
        
        return df_processed, X_scaled, scaler
    
    @st.cache_data
    def calculate_elbow_method(_self, X_scaled, k_range=(1, 11)):
        """
        TÃ­nh toÃ¡n inertia vÃ  silhouette scores cho cÃ¡c giÃ¡ trá»‹ K.
        ÄÆ°á»£c cache Ä‘á»ƒ tá»‘i Æ°u hiá»‡u suáº¥t.
        """
        inertia_values = []
        silhouette_scores = []
        K_range = range(k_range[0], k_range[1])
        
        for k in K_range:
            kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)
            kmeans.fit(X_scaled)
            inertia_values.append(kmeans.inertia_)
            
            # TÃ­nh Silhouette Score (chá»‰ cho k >= 2)
            if k >= 2:
                score = silhouette_score(X_scaled, kmeans.labels_)
                silhouette_scores.append(score)
            else:
                silhouette_scores.append(0)
        
        return K_range, inertia_values, silhouette_scores
    
    def train_model(self, X_scaled, n_clusters=4):
        # Huáº¥n luyá»‡n mÃ´ hÃ¬nh K-Means vÃ  lÆ°u vÃ o file .pkl.

        # Huáº¥n luyá»‡n mÃ´ hÃ¬nh
        kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)
        cluster_labels = kmeans.fit_predict(X_scaled)
        
        # LÆ°u mÃ´ hÃ¬nh vÃ  scaler
        self.model = kmeans
        joblib.dump(kmeans, self.model_path)
        joblib.dump(self.scaler, self.scaler_path)
        
        # ThÃªm nhÃ£n cá»¥m vÃ o dataframe
        df_with_clusters = self.df_processed.copy()
        df_with_clusters['Cluster'] = cluster_labels
        df_with_clusters['Cluster'] = df_with_clusters['Cluster'].astype(str)
        
        # PhÃ¢n tÃ­ch vÃ  gÃ¡n nhÃ£n Ä‘á»™ng cho cÃ¡c cá»¥m
        self._analyze_and_label_clusters(df_with_clusters)
        
        # LÆ°u mapping
        joblib.dump(self.cluster_label_mapping, self.mapping_path)
        
        return kmeans, cluster_labels, df_with_clusters
    
    def _analyze_and_label_clusters(self, df_with_clusters):
        # PhÃ¢n tÃ­ch cÃ¡c cá»¥m vÃ  gÃ¡n nhÃ£n thÃ´ng minh (Dynamic Labeling Logic).
        
        # TÃ­nh trung bÃ¬nh toÃ n cá»¥c
        avg_qty_all = df_with_clusters['quantity'].mean()
        avg_rating_all = df_with_clusters['avg_rating'].mean()
        
        # TÃ­nh trung bÃ¬nh theo cá»¥m
        cluster_stats = df_with_clusters.groupby('Cluster').agg({
            'quantity': 'mean',
            'avg_rating': 'mean'
        })
        
        # TÃ¬m cá»¥m cÃ³ lÆ°á»£ng bÃ¡n cao nháº¥t -> Xu HÆ°á»›ng
        trend_cluster_id = cluster_stats['quantity'].idxmax()
        
        # Khá»Ÿi táº¡o mapping
        self.cluster_label_mapping = {}
        
        # PhÃ¢n tÃ­ch tá»«ng cá»¥m
        for cluster_id in sorted(df_with_clusters['Cluster'].unique()):
            mean_qty = cluster_stats.loc[cluster_id, 'quantity']
            mean_rating = cluster_stats.loc[cluster_id, 'avg_rating']
            
            # Logic gÃ¡n nhÃ£n 
            if cluster_id == trend_cluster_id:
                label = "ğŸ”¥ Xu HÆ°á»›ng (Best-Seller)"
            elif mean_qty < avg_qty_all and mean_rating >= avg_rating_all:
                label = "ğŸ’ Tiá»m NÄƒng (KÃ©n KhÃ¡ch)"
            elif mean_qty < avg_qty_all and mean_rating < avg_rating_all:
                label = "âš ï¸ Rá»§i Ro (Cáº§n Cáº£i Thiá»‡n)"
            else:
                label = "ğŸ“š Phá»• ThÃ´ng (BÃ¡n á»”n Äá»‹nh)"
            
            self.cluster_label_mapping[str(cluster_id)] = label
    
    def get_cluster_label_name(self, cluster_id):
        # Láº¥y tÃªn nhÃ£n cá»§a cá»¥m tá»« cluster_id.

        cluster_id_str = str(cluster_id)
        return self.cluster_label_mapping.get(cluster_id_str, "Unknown")
    
    def load_saved_model(self):
        try:
            if os.path.exists(self.model_path) and os.path.exists(self.scaler_path) and os.path.exists(self.mapping_path):
                self.model = joblib.load(self.model_path)
                self.scaler = joblib.load(self.scaler_path)
                self.cluster_label_mapping = joblib.load(self.mapping_path)
                return True
            return False
        except Exception as e:
            st.error(f"Lá»—i khi táº£i mÃ´ hÃ¬nh: {str(e)}")
            return False
    
    def predict_new_book(self, quantity, n_review, rating):
        # Kiá»ƒm tra xem mÃ´ hÃ¬nh Ä‘Ã£ Ä‘Æ°á»£c huáº¥n luyá»‡n chÆ°a
        if self.model is None or self.scaler is None:
            # Thá»­ táº£i mÃ´ hÃ¬nh Ä‘Ã£ lÆ°u
            if not self.load_saved_model():
                return {
                    'error': 'MÃ´ hÃ¬nh chÆ°a Ä‘Æ°á»£c huáº¥n luyá»‡n. Vui lÃ²ng huáº¥n luyá»‡n mÃ´ hÃ¬nh á»Ÿ Tab Dashboard trÆ°á»›c.'
                }
        
        # Chuáº©n bá»‹ dá»¯ liá»‡u Ä‘áº§u vÃ o (sá»­ dá»¥ng DataFrame Ä‘á»ƒ trÃ¡nh warning vá» feature names)
        input_data = pd.DataFrame({
            'quantity': [quantity],
            'n_review': [n_review],
            'avg_rating': [rating]
        })
        
        # Chuáº©n hÃ³a
        input_scaled = self.scaler.transform(input_data)
        
        # Dá»± bÃ¡o
        cluster_id = self.model.predict(input_scaled)[0]
        cluster_id_str = str(cluster_id)
        
        # Láº¥y nhÃ£n
        cluster_label = self.get_cluster_label_name(cluster_id_str)
        
        # Táº¡o lá»i khuyÃªn dá»±a trÃªn nhÃ£n cá»¥m
        advice = self._get_business_advice(cluster_label)
        
        return {
            'cluster_id': cluster_id_str,
            'cluster_label': cluster_label,
            'manager_advice': advice['manager'],
            'marketing_action': advice['marketing']
        }
    
    def _get_business_advice(self, cluster_label):
        # Lá»i khuyÃªn kinh doanh dá»±a trÃªn nhÃ£n cá»¥m.
        advice_map = {
            "ğŸ”¥ Xu HÆ°á»›ng (Best-Seller)": {
                "manager": "Nháº­p sá»‘ lÆ°á»£ng lá»›n. Äáº£m báº£o tá»“n kho > 500 cuá»‘n.",
                "marketing": "Æ¯u tiÃªn trÆ°ng bÃ y táº¡i trang chá»§/ká»‡ Hot. Cháº¡y Ads ngÃ¢n sÃ¡ch cao."
            },
            "ğŸ’ Tiá»m NÄƒng (KÃ©n KhÃ¡ch)": {
                "manager": "Nháº­p sá»‘ lÆ°á»£ng vá»«a pháº£i. Theo dÃµi ká»¹ review.",
                "marketing": "Viáº¿t content review sÃ¢u sáº¯c. Target nhÃ³m khÃ¡ch hÃ ng chuyÃªn biá»‡t."
            },
            "âš ï¸ Rá»§i Ro (Cáº§n Cáº£i Thiá»‡n)": {
                "manager": "Háº¡n cháº¿ nháº­p thÃªm. CÃ¢n nháº¯c xáº£ hÃ ng.",
                "marketing": "Táº¡o Flash Sale giáº£m giÃ¡ sÃ¢u Ä‘á»ƒ Ä‘áº©y hÃ ng tá»“n."
            },
            "ğŸ“š Phá»• ThÃ´ng (BÃ¡n á»”n Äá»‹nh)": {
                "manager": "Duy trÃ¬ má»©c nháº­p trung bÃ¬nh.",
                "marketing": "BÃ¡n kÃ¨m combo khuyáº¿n mÃ£i. PhÃ¹ há»£p bÃ¡n trÃªn sÃ n TMÄT."
            }
        }
        
        return advice_map.get(cluster_label, {
            "manager": "ChÆ°a cÃ³ dá»¯ liá»‡u Ä‘á»§ Ä‘á»ƒ Ä‘Æ°a ra lá»i khuyÃªn.",
            "marketing": "ChÆ°a cÃ³ gá»£i Ã½ marketing cá»¥ thá»ƒ."
        })
    
    def get_cluster_statistics(self, df_with_clusters):
        # TÃ­nh toÃ¡n thá»‘ng kÃª theo cá»¥m.

        stats = df_with_clusters.groupby('Cluster')[self.features].mean()
        stats = stats.round(2)
        
        # ThÃªm cá»™t nhÃ£n
        stats['NhÃ£n Cá»¥m'] = [self.get_cluster_label_name(cluster_id) for cluster_id in stats.index]
        
        # Äá»•i tÃªn cá»™t sang tiáº¿ng Viá»‡t
        stats.columns = ['Sá»‘ lÆ°á»£ng bÃ¡n TB', 'Sá»‘ Ä‘Ã¡nh giÃ¡ TB', 'Rating TB', 'NhÃ£n Cá»¥m']
        
        return stats
